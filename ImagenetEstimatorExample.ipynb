{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import iglob\n",
    "from itertools import chain\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os import path\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join(os.getenv('AZ_BATCHAI_INPUT_DATASET'), 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_csv(path.join(data_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(filenames=train_df.filenames.apply(lambda x: path.join(data_dir,'train', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>wnid</th>\n",
       "      <th>num_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/input/imagenet/train/n02119789/n02119789_...</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/input/imagenet/train/n02119789/n02119789_...</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/input/imagenet/train/n02119789/n02119789_...</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/input/imagenet/train/n02119789/n02119789_...</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/input/imagenet/train/n02119789/n02119789_...</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames       wnid  num_id\n",
       "0  /mnt/input/imagenet/train/n02119789/n02119789_...  n02119789       1\n",
       "1  /mnt/input/imagenet/train/n02119789/n02119789_...  n02119789       1\n",
       "2  /mnt/input/imagenet/train/n02119789/n02119789_...  n02119789       1\n",
       "3  /mnt/input/imagenet/train/n02119789/n02119789_...  n02119789       1\n",
       "4  /mnt/input/imagenet/train/n02119789/n02119789_...  n02119789       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "validation_df = pd.DataFrame.from_csv(path.join(data_dir, 'validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validation_df.assign(filenames=validation_df.filenames.apply(lambda x: path.join(data_dir,'validation', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>num_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/input/imagenet/validation/ILSVRC2012_val_...</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/input/imagenet/validation/ILSVRC2012_val_...</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/input/imagenet/validation/ILSVRC2012_val_...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/input/imagenet/validation/ILSVRC2012_val_...</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/input/imagenet/validation/ILSVRC2012_val_...</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames  num_id\n",
       "0  /mnt/input/imagenet/validation/ILSVRC2012_val_...     490\n",
       "1  /mnt/input/imagenet/validation/ILSVRC2012_val_...     361\n",
       "2  /mnt/input/imagenet/validation/ILSVRC2012_val_...     171\n",
       "3  /mnt/input/imagenet/validation/ILSVRC2012_val_...     822\n",
       "4  /mnt/input/imagenet/validation/ILSVRC2012_val_...     297"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1281167, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['num_id']].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = oh_encoder.fit_transform(train_df[['num_id']].values).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = oh_encoder.transform(validation_df[['num_id']].values).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_df['filenames'].values, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "LR = 0.0001\n",
    "EPOCHS = 5\n",
    "BATCHSIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_RGB_MEAN_CAFFE = np.array([123.68, 116.78, 103.94], dtype=np.float32)\n",
    "IMAGENET_SCALE_FACTOR_CAFFE = 0.017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = IMAGENET_RGB_MEAN_CAFFE\n",
    "imagenet_scaling = IMAGENET_SCALE_FACTOR_CAFFE\n",
    "width = WIDTH\n",
    "height = HEIGHT\n",
    "buffer=10\n",
    "batch_size=BATCHSIZE\n",
    "data_length = len(train_df)\n",
    "validation_length = len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_image_labels(filename, label):\n",
    "        # load and preprocess the image\n",
    "        img_decoded = tf.to_float(tf.image.decode_png(tf.read_file(filename), channels=3))\n",
    "        img_decoded = tf.image.resize_images(img_decoded, [WIDTH, HEIGHT])\n",
    "        img_centered = tf.subtract(img_decoded, imagenet_mean)\n",
    "        img_rgb = img_centered * imagenet_scaling\n",
    "        return img_rgb, tf.cast(label, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function_train(filename, label):\n",
    "        img_rgb, label = _preprocess_image_labels(filename, label)\n",
    "        # Random crop (from 264x264)\n",
    "        img_rgb = tf.random_crop(img_rgb, [height, width, 3])\n",
    "        # Random flip\n",
    "        img_rgb = tf.image.random_flip_left_right(img_rgb)\n",
    "        # Channels-first\n",
    "        img_rgb = tf.transpose(img_rgb, [2, 0, 1])\n",
    "        return img_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function_train(filename, label):\n",
    "        img_rgb, label = _preprocess_image_labels(filename, label)\n",
    "        # Channels-first\n",
    "        img_rgb = tf.transpose(img_rgb, [2, 0, 1])\n",
    "        return img_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_transform = tf.contrib.data.map_and_batch(_parse_function_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (train_data.shuffle(len(train_df))\n",
    "                        .repeat()\n",
    "                        .apply(train_data_transform)\n",
    "                        .prefetch(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = tf.data.Dataset.from_tensor_slices((validation_df['filenames'].values, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_transform = tf.contrib.data.map_and_batch(_parse_function_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (validation_data.repeat()\n",
    "                        .apply(validation_data_transform)\n",
    "                        .prefetch(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return train_data.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_input_fn():\n",
    "    return validation_data.make_one_shot_iterator().get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Args:\n",
    "    #\n",
    "    # features: This is the x-arg from the input_fn.\n",
    "    # labels:   This is the y-arg from the input_fn,\n",
    "    #           see e.g. train_input_fn for these two.\n",
    "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
    "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
    "    \n",
    "    # Reference to the tensor named \"x\" in the input-function.\n",
    "    x = features\n",
    "\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    net = tf.reshape(x, [-1, width, height, CHANNELS])    \n",
    "\n",
    "    # First convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='b1_conv1',\n",
    "                           filters=64, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.conv2d(inputs=net, name='b1_conv2',\n",
    "                           filters=64, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='b2_conv1',\n",
    "                           filters=128, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.conv2d(inputs=net, name='b2_conv2',\n",
    "                           filters=128, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)  \n",
    "    \n",
    "    # Third convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='b3_conv1',\n",
    "                           filters=256, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.conv2d(inputs=net, name='b3_conv2',\n",
    "                           filters=256, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.conv2d(inputs=net, name='b3_conv3',\n",
    "                           filters=256, kernel_size=3,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2) \n",
    "\n",
    "    # Flatten to a 2-rank tensor.\n",
    "    net = tf.layers.flatten(net)\n",
    "    \n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                          units=2048, activation=tf.nn.relu)    \n",
    "\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc2',\n",
    "                          units=1000)\n",
    "\n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': y_pred_cls,\n",
    "            'probabilities': y_pred,\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions)\n",
    "    \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1),\n",
    "                                   predictions=y_pred_cls,\n",
    "                                   name='acc_op')\n",
    "        metrics = {'accuracy': accuracy}\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                eval_metric_ops=metrics,\n",
    "                loss=loss)\n",
    "\n",
    "    # Define the optimizer for improving the neural network.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "\n",
    "    # Get the TensorFlow op for doing a single optimization step.\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"learning_rate\": 1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /mnt/model/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfig = tf.estimator.RunConfig(save_checkpoints_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_tf_random_seed': None, '_num_ps_replicas': 0, '_task_type': 'worker', '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faba5e44550>, '_num_worker_replicas': 1, '_task_id': 0, '_evaluation_master': '', '_service': None, '_model_dir': '/mnt/model', '_save_checkpoints_secs': None, '_save_checkpoints_steps': 1000, '_session_config': None, '_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=os.getenv('AZ_BATCHAI_OUTPUT_MODEL'),\n",
    "                               config=rfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-29-802e39102068>:75: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.9115324, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.907812.\n",
      "evaluating\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-09-13:19:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-09-13:19:47\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.003125, global_step = 10, loss = 6.9131308\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 11 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.9058495, step = 11\n",
      "INFO:tensorflow:Saving checkpoints for 20 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.907934.\n",
      "evaluating\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-09-13:26:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-09-13:26:13\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.0, global_step = 20, loss = 6.907933\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 21 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.918858, step = 21\n",
      "INFO:tensorflow:Saving checkpoints for 30 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.8998446.\n",
      "evaluating\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-09-13:32:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-30\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-09-13:32:44\n",
      "INFO:tensorflow:Saving dict for global step 30: accuracy = 0.0, global_step = 30, loss = 6.907937\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-30\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 31 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.909786, step = 31\n",
      "INFO:tensorflow:Saving checkpoints for 40 into /mnt/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.9020333.\n",
      "evaluating\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-09-13:41:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-40\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-09-13:41:14\n",
      "INFO:tensorflow:Saving dict for global step 40: accuracy = 0.0, global_step = 40, loss = 6.909429\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/model/model.ckpt-40\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 41 into /mnt/model/model.ckpt.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "/mnt/model/model.ckpt-41_temp_923ce82845fc492eb0423b507375e179/part-00000-of-00001.data-00000-of-00001.tempstate18363108291152576982; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, b1_conv1/bias/_371, b1_conv1/bias/Adam/_373, b1_conv1/bias/Adam_1/_375, b1_conv1/kernel/_377, b1_conv1/kernel/Adam/_379, b1_conv1/kernel/Adam_1/_381, b1_conv2/bias/_383, b1_conv2/bias/Adam/_385, b1_conv2/bias/Adam_1/_387, b1_conv2/kernel/_389, b1_conv2/kernel/Adam/_391, b1_conv2/kernel/Adam_1/_393, b2_conv1/bias/_395, b2_conv1/bias/Adam/_397, b2_conv1/bias/Adam_1/_399, b2_conv1/kernel/_401, b2_conv1/kernel/Adam/_403, b2_conv1/kernel/Adam_1/_405, b2_conv2/bias/_407, b2_conv2/bias/Adam/_409, b2_conv2/bias/Adam_1/_411, b2_conv2/kernel/_413, b2_conv2/kernel/Adam/_415, b2_conv2/kernel/Adam_1/_417, b3_conv1/bias/_419, b3_conv1/bias/Adam/_421, b3_conv1/bias/Adam_1/_423, b3_conv1/kernel/_425, b3_conv1/kernel/Adam/_427, b3_conv1/kernel/Adam_1/_429, b3_conv2/bias/_431, b3_conv2/bias/Adam/_433, b3_conv2/bias/Adam_1/_435, b3_conv2/kernel/_437, b3_conv2/kernel/Adam/_439, b3_conv2/kernel/Adam_1/_441, b3_conv3/bias/_443, b3_conv3/bias/Adam/_445, b3_conv3/bias/Adam_1/_447, b3_conv3/kernel/_449, b3_conv3/kernel/Adam/_451, b3_conv3/kernel/Adam_1/_453, beta1_power/_455, beta2_power/_457, global_step, layer_fc1/bias/_459, layer_fc1/bias/Adam/_461, layer_fc1/bias/Adam_1/_463, layer_fc1/kernel/_465, layer_fc1/kernel/Adam/_467, layer_fc1/kernel/Adam_1/_469, layer_fc2/bias/_471, layer_fc2/bias/Adam/_473, layer_fc2/bias/Adam_1/_475, layer_fc2/kernel/_477, layer_fc2/kernel/Adam/_479, layer_fc2/kernel/Adam_1/_481)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-302a3a952cac>\", line 2, in <module>\n    model.train(input_fn=train_input_fn, steps=10) #data_length//batch_size\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 352, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 888, in _train_model\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 787, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 411, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 385, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 241, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1173, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): /mnt/model/model.ckpt-41_temp_923ce82845fc492eb0423b507375e179/part-00000-of-00001.data-00000-of-00001.tempstate18363108291152576982; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, b1_conv1/bias/_371, b1_conv1/bias/Adam/_373, b1_conv1/bias/Adam_1/_375, b1_conv1/kernel/_377, b1_conv1/kernel/Adam/_379, b1_conv1/kernel/Adam_1/_381, b1_conv2/bias/_383, b1_conv2/bias/Adam/_385, b1_conv2/bias/Adam_1/_387, b1_conv2/kernel/_389, b1_conv2/kernel/Adam/_391, b1_conv2/kernel/Adam_1/_393, b2_conv1/bias/_395, b2_conv1/bias/Adam/_397, b2_conv1/bias/Adam_1/_399, b2_conv1/kernel/_401, b2_conv1/kernel/Adam/_403, b2_conv1/kernel/Adam_1/_405, b2_conv2/bias/_407, b2_conv2/bias/Adam/_409, b2_conv2/bias/Adam_1/_411, b2_conv2/kernel/_413, b2_conv2/kernel/Adam/_415, b2_conv2/kernel/Adam_1/_417, b3_conv1/bias/_419, b3_conv1/bias/Adam/_421, b3_conv1/bias/Adam_1/_423, b3_conv1/kernel/_425, b3_conv1/kernel/Adam/_427, b3_conv1/kernel/Adam_1/_429, b3_conv2/bias/_431, b3_conv2/bias/Adam/_433, b3_conv2/bias/Adam_1/_435, b3_conv2/kernel/_437, b3_conv2/kernel/Adam/_439, b3_conv2/kernel/Adam_1/_441, b3_conv3/bias/_443, b3_conv3/bias/Adam/_445, b3_conv3/bias/Adam_1/_447, b3_conv3/kernel/_449, b3_conv3/kernel/Adam/_451, b3_conv3/kernel/Adam_1/_453, beta1_power/_455, beta2_power/_457, global_step, layer_fc1/bias/_459, layer_fc1/bias/Adam/_461, layer_fc1/bias/Adam_1/_463, layer_fc1/kernel/_465, layer_fc1/kernel/Adam/_467, layer_fc1/kernel/Adam_1/_469, layer_fc2/bias/_471, layer_fc2/bias/Adam/_473, layer_fc2/bias/Adam_1/_475, layer_fc2/kernel/_477, layer_fc2/kernel/Adam/_479, layer_fc2/kernel/Adam_1/_481)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /mnt/model/model.ckpt-41_temp_923ce82845fc492eb0423b507375e179/part-00000-of-00001.data-00000-of-00001.tempstate18363108291152576982; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, b1_conv1/bias/_371, b1_conv1/bias/Adam/_373, b1_conv1/bias/Adam_1/_375, b1_conv1/kernel/_377, b1_conv1/kernel/Adam/_379, b1_conv1/kernel/Adam_1/_381, b1_conv2/bias/_383, b1_conv2/bias/Adam/_385, b1_conv2/bias/Adam_1/_387, b1_conv2/kernel/_389, b1_conv2/kernel/Adam/_391, b1_conv2/kernel/Adam_1/_393, b2_conv1/bias/_395, b2_conv1/bias/Adam/_397, b2_conv1/bias/Adam_1/_399, b2_conv1/kernel/_401, b2_conv1/kernel/Adam/_403, b2_conv1/kernel/Adam_1/_405, b2_conv2/bias/_407, b2_conv2/bias/Adam/_409, b2_conv2/bias/Adam_1/_411, b2_conv2/kernel/_413, b2_conv2/kernel/Adam/_415, b2_conv2/kernel/Adam_1/_417, b3_conv1/bias/_419, b3_conv1/bias/Adam/_421, b3_conv1/bias/Adam_1/_423, b3_conv1/kernel/_425, b3_conv1/kernel/Adam/_427, b3_conv1/kernel/Adam_1/_429, b3_conv2/bias/_431, b3_conv2/bias/Adam/_433, b3_conv2/bias/Adam_1/_435, b3_conv2/kernel/_437, b3_conv2/kernel/Adam/_439, b3_conv2/kernel/Adam_1/_441, b3_conv3/bias/_443, b3_conv3/bias/Adam/_445, b3_conv3/bias/Adam_1/_447, b3_conv3/kernel/_449, b3_conv3/kernel/Adam/_451, b3_conv3/kernel/Adam_1/_453, beta1_power/_455, beta2_power/_457, global_step, layer_fc1/bias/_459, layer_fc1/bias/Adam/_461, layer_fc1/bias/Adam_1/_463, layer_fc1/kernel/_465, layer_fc1/kernel/Adam/_467, layer_fc1/kernel/Adam_1/_469, layer_fc2/bias/_471, layer_fc2/bias/Adam/_473, layer_fc2/bias/Adam_1/_475, layer_fc2/kernel/_477, layer_fc2/kernel/Adam/_479, layer_fc2/kernel/Adam_1/_481)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-302a3a952cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#data_length//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#validation_length//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1176\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1179\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m    456\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_trigger_for_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, session, step)\u001b[0m\n\u001b[1;32m    472\u001b[0m       \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     self._summary_writer.add_session_log(\n\u001b[1;32m    476\u001b[0m         SessionLog(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1652\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1653\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1655\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /mnt/model/model.ckpt-41_temp_923ce82845fc492eb0423b507375e179/part-00000-of-00001.data-00000-of-00001.tempstate18363108291152576982; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, b1_conv1/bias/_371, b1_conv1/bias/Adam/_373, b1_conv1/bias/Adam_1/_375, b1_conv1/kernel/_377, b1_conv1/kernel/Adam/_379, b1_conv1/kernel/Adam_1/_381, b1_conv2/bias/_383, b1_conv2/bias/Adam/_385, b1_conv2/bias/Adam_1/_387, b1_conv2/kernel/_389, b1_conv2/kernel/Adam/_391, b1_conv2/kernel/Adam_1/_393, b2_conv1/bias/_395, b2_conv1/bias/Adam/_397, b2_conv1/bias/Adam_1/_399, b2_conv1/kernel/_401, b2_conv1/kernel/Adam/_403, b2_conv1/kernel/Adam_1/_405, b2_conv2/bias/_407, b2_conv2/bias/Adam/_409, b2_conv2/bias/Adam_1/_411, b2_conv2/kernel/_413, b2_conv2/kernel/Adam/_415, b2_conv2/kernel/Adam_1/_417, b3_conv1/bias/_419, b3_conv1/bias/Adam/_421, b3_conv1/bias/Adam_1/_423, b3_conv1/kernel/_425, b3_conv1/kernel/Adam/_427, b3_conv1/kernel/Adam_1/_429, b3_conv2/bias/_431, b3_conv2/bias/Adam/_433, b3_conv2/bias/Adam_1/_435, b3_conv2/kernel/_437, b3_conv2/kernel/Adam/_439, b3_conv2/kernel/Adam_1/_441, b3_conv3/bias/_443, b3_conv3/bias/Adam/_445, b3_conv3/bias/Adam_1/_447, b3_conv3/kernel/_449, b3_conv3/kernel/Adam/_451, b3_conv3/kernel/Adam_1/_453, beta1_power/_455, beta2_power/_457, global_step, layer_fc1/bias/_459, layer_fc1/bias/Adam/_461, layer_fc1/bias/Adam_1/_463, layer_fc1/kernel/_465, layer_fc1/kernel/Adam/_467, layer_fc1/kernel/Adam_1/_469, layer_fc2/bias/_471, layer_fc2/bias/Adam/_473, layer_fc2/bias/Adam_1/_475, layer_fc2/kernel/_477, layer_fc2/kernel/Adam/_479, layer_fc2/kernel/Adam_1/_481)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-302a3a952cac>\", line 2, in <module>\n    model.train(input_fn=train_input_fn, steps=10) #data_length//batch_size\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 352, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 888, in _train_model\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 787, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 411, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 385, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 241, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1173, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): /mnt/model/model.ckpt-41_temp_923ce82845fc492eb0423b507375e179/part-00000-of-00001.data-00000-of-00001.tempstate18363108291152576982; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, b1_conv1/bias/_371, b1_conv1/bias/Adam/_373, b1_conv1/bias/Adam_1/_375, b1_conv1/kernel/_377, b1_conv1/kernel/Adam/_379, b1_conv1/kernel/Adam_1/_381, b1_conv2/bias/_383, b1_conv2/bias/Adam/_385, b1_conv2/bias/Adam_1/_387, b1_conv2/kernel/_389, b1_conv2/kernel/Adam/_391, b1_conv2/kernel/Adam_1/_393, b2_conv1/bias/_395, b2_conv1/bias/Adam/_397, b2_conv1/bias/Adam_1/_399, b2_conv1/kernel/_401, b2_conv1/kernel/Adam/_403, b2_conv1/kernel/Adam_1/_405, b2_conv2/bias/_407, b2_conv2/bias/Adam/_409, b2_conv2/bias/Adam_1/_411, b2_conv2/kernel/_413, b2_conv2/kernel/Adam/_415, b2_conv2/kernel/Adam_1/_417, b3_conv1/bias/_419, b3_conv1/bias/Adam/_421, b3_conv1/bias/Adam_1/_423, b3_conv1/kernel/_425, b3_conv1/kernel/Adam/_427, b3_conv1/kernel/Adam_1/_429, b3_conv2/bias/_431, b3_conv2/bias/Adam/_433, b3_conv2/bias/Adam_1/_435, b3_conv2/kernel/_437, b3_conv2/kernel/Adam/_439, b3_conv2/kernel/Adam_1/_441, b3_conv3/bias/_443, b3_conv3/bias/Adam/_445, b3_conv3/bias/Adam_1/_447, b3_conv3/kernel/_449, b3_conv3/kernel/Adam/_451, b3_conv3/kernel/Adam_1/_453, beta1_power/_455, beta2_power/_457, global_step, layer_fc1/bias/_459, layer_fc1/bias/Adam/_461, layer_fc1/bias/Adam_1/_463, layer_fc1/kernel/_465, layer_fc1/kernel/Adam/_467, layer_fc1/kernel/Adam_1/_469, layer_fc2/bias/_471, layer_fc2/bias/Adam/_473, layer_fc2/bias/Adam_1/_475, layer_fc2/kernel/_477, layer_fc2/kernel/Adam/_479, layer_fc2/kernel/Adam_1/_481)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train(input_fn=train_input_fn, steps=10) #data_length//batch_size\n",
    "    print('evaluating')\n",
    "    model.evaluate(input_fn=validation_input_fn, steps=10) #validation_length//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
